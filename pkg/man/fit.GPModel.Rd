% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GPModel.R
\name{fit.GPModel}
\alias{fit.GPModel}
\title{Fits a \code{GPModel}}
\usage{
\method{fit}{GPModel}(gp_model, y, X = NULL, std_dev = FALSE,
  params = list(optimizer_cov = "fisher_scoring", optimizer_coef = "wls",
  maxit = 1000, delta_rel_conv = 1e-06, init_coef = NULL, init_cov_pars = NULL,
  lr_coef = 0.01, lr_cov = -1, use_nesterov_acc = FALSE, acc_rate_coef = 0.1,
  acc_rate_cov = 0.5, nesterov_schedule_version = 0L, momentum_offset = 2L,
  trace = FALSE, convergence_criterion = "relative_change_in_log_likelihood"))
}
\arguments{
\item{gp_model}{a \code{GPModel}}

\item{y}{A \code{vector} with response variable data}

\item{X}{A \code{matrix} with covariate data for fixed effects ( = linear regression term)}

\item{std_dev}{If TRUE (asymptotic) standard deviations are calculated for all parameters}

\item{params}{A \code{list} with parameters for the model fitting / optimization
 \itemize{
    \item{optimizer_cov}{ Optimizer used for estimating covariance parameters. 
    Options: "gradient_descent" or "fisher_scoring". Default="fisher_scoring".}
    \item{optimizer_coef}{ Optimizer used for estimating linear regression coefficients, if there are any 
    (for the GPBoost algorithm there are usually no). 
    Options: "gradient_descent" or "wls". Gradient descent steps are done simultaneously 
    with gradient descent steps for the covariance paramters. 
    "wls" refers to doing coordinate descent for the regression coefficients using weighted least squares.
    Default="wls".}
    \item{maxit}{ Maximal number of iterations for optimization algorithm. Default=1000.}
    \item{delta_rel_conv}{ Convergence criterion: stop optimization if relative change 
    in parameters is below this value. Default=1E-6.}
    \item{init_coef}{ Initial values for the regression coefficients (if there are any, can be NULL).
    Default=NULL.}
    \item{init_cov_pars}{ Initial values for covariance parameters of Gaussian process and 
    random effects (can be NULL). Default=NULL.}
    \item{lr_coef}{ Learning rate for fixed effect regression coefficients if gradient descent is used.
    Default=0.01.}
    \item{lr_cov}{ Learning rate for covariance parameters. If <= 0, internal default values are used.
    Default value = 0.01 for "gradient_descent" and 1. for "fisher_scoring"}
    \item{use_nesterov_acc}{ If TRUE Nesterov acceleration is used. Default=FALSE.}
    \item{acc_rate_coef}{ Acceleration rate for regression coefficients (if there are any) 
    for Nesterov acceleration. Default=0.1.}
    \item{acc_rate_cov}{ Acceleration rate for covariance parameters for Nesterov acceleration.
    Default=0.5.}
    \item{momentum_offset}{ Number of iterations for which no mometum is applied in the beginning.
    Default=2.}
    \item{trace}{ If TRUE, the value of the gradient is printed for some iterations.
    Useful for finding good learning rates. Default=FALSE.}
    \item{convergence_criterion}{ The convergence criterion used for terminating the optimization algorithm.
    Options: "relative_change_in_log_likelihood" (default) or "relative_change_in_parameters".}
}}
}
\value{
A fitted \code{GPModel}
}
\description{
Estimates the parameters of a \code{GPModel} using maximum likelihood estimation
}
\examples{
## SEE ALSO THE HELP OF 'fitGPModel' FOR MORE EXAMPLES
library(gpboost)

\dontrun{
#--------------------Grouped random effects model: single-level random effect----------------
n <- 100 # number of samples
m <- 25 # number of categories / levels for grouping variable
group <- rep(1,n) # grouping variable
for(i in 1:m) group[((i-1)*n/m+1):(i*n/m)] <- i
# Create random effects model
gp_model <- GPModel(group_data = group)

# Simulate data
sigma2_1 <- 1^2 # random effect variance
sigma2 <- 0.5^2 # error variance
 # incidence matrix relating grouped random effects to samples
Z1 <- model.matrix(rep(1,n) ~ factor(group) - 1)
set.seed(1)
b1 <- sqrt(sigma2_1) * rnorm(m) # simulate random effects
eps <- Z1 \%*\% b1
xi <- sqrt(sigma2) * rnorm(n) # simulate error term
y <- eps + xi # observed data
# Fit model
fit(gp_model, y = y, std_dev = TRUE)
summary(gp_model)
# Alternatively, define and fit model directly using fitGPModel
gp_model <- fitGPModel(group_data = group, y = y, std_dev = TRUE)
summary(gp_model)

# Make predictions
group_test <- 1:m
pred <- predict(gp_model, group_data_pred = group_test)
# Compare true and predicted random effects
plot(b1, pred$mu, xlab="truth", ylab="predicted",
     main="Comparison of true and predicted random effects")
abline(a=0,b=1)
# Also predict covariance matrix
pred <- predict(gp_model, group_data_pred = c(1,1,2,2,-1,-1), predict_cov_mat = TRUE)
pred$mu# Predicted mean
pred$cov# Predicted covariance

# Use other optimization technique: gradient descent instead of Fisher scoring
gp_model <- fitGPModel(group_data = group, y = y, std_dev = TRUE,
                       params = list(optimizer_cov = "gradient_descent",
                                     lr_cov = 0.1, use_nesterov_acc = FALSE))
summary(gp_model)

# Evaluate negative log-likelihood
gp_model$neg_log_likelihood(cov_pars=c(sigma2,sigma2_1),y=y)
# Do optimization using optim and e.g. Nelder-Mead
gp_model <- GPModel(group_data = group)
optim(par=c(1,1), fn=gp_model$neg_log_likelihood, y=y, method="Nelder-Mead")
 
 
#--------------------Gaussian process model----------------
n <- 200 # number of samples
set.seed(1)
coords <- cbind(runif(n),runif(n)) # locations (=features) for Gaussian process
# Create Gaussian process model
gp_model <- GPModel(gp_coords = coords, cov_function = "exponential")
## Other covariance functions:
# gp_model <- GPModel(gp_coords = coords, cov_function = "gaussian")
# gp_model <- GPModel(gp_coords = coords,
#                     cov_function = "matern", cov_fct_shape=1.5)
# gp_model <- GPModel(gp_coords = coords,
#                     cov_function = "powered_exponential", cov_fct_shape=1.1)
# Simulate data
sigma2_1 <- 1^2 # marginal variance of GP
rho <- 0.1 # range parameter
sigma2 <- 0.5^2 # error variance
D <- as.matrix(dist(coords))
Sigma = sigma2_1*exp(-D/rho)+diag(1E-20,n)
C = t(chol(Sigma))
b_1=rnorm(n) # simulate random effect
eps <- C \%*\% b_1
xi <- sqrt(sigma2) * rnorm(n) # simulate error term
y <- eps + xi
# Fit model
fit(gp_model, y = y, std_dev = TRUE)
summary(gp_model)
# Alternatively, define and fit model directly using fitGPModel
gp_model <- fitGPModel(gp_coords = coords, cov_function = "exponential",
                        y = y, std_dev = TRUE)
summary(gp_model)

# Make predictions
set.seed(1)
ntest <- 5
# prediction locations (=features) for Gaussian process
coords_test <- cbind(runif(ntest),runif(ntest))/10
pred <- predict(gp_model, gp_coords_pred = coords_test,
                predict_cov_mat = TRUE)
print("Predicted (posterior/conditional) mean of GP")
pred$mu
print("Predicted (posterior/conditional) covariance matrix of GP")
pred$cov

# Use other optimization technique: Nesterov accelerated gradient descent instead of Fisher scoring
gp_model <- fitGPModel(gp_coords = coords, cov_function = "exponential",
                       y = y, std_dev = TRUE,
                       params = list(optimizer_cov = "gradient_descent",
                                     lr_cov = 0.05, use_nesterov_acc = TRUE))
summary(gp_model)

# Evaluate negative log-likelihood
gp_model$neg_log_likelihood(cov_pars=c(sigma2,sigma2_1,rho),y=y)
# Do optimization using optim and e.g. Nelder-Mead
gp_model <- GPModel(gp_coords = coords, cov_function = "exponential")
optim(par=c(1,1,0.2), fn=gp_model$neg_log_likelihood, y=y, method="Nelder-Mead")
}

}
